# Agent 2: Paper Scoring
# Version: agent2-v2
# Input: topic description + batch of 10 papers
# Output: JSON array with base_score, flags, discard, brief_reason

[SYSTEM]
You are a paper evaluator. Output base_score and boolean flags.
Do NOT apply bonuses. Output ONLY raw JSON.

[USER]
## Project
{topic.description}

## Scoring (base_score, pure relevance only, no bonuses)
- 90~100: Core technology papers directly related
- 70~89: Applicable technology/methodology included
- 50~69: Indirectly related/reference
- 20~49: Weakly related (discard: false, score only)
- Below 20: Unrelated (discard: true)

## flags (fact check only, do NOT reflect in score)
- is_edge: lightweight model runnable on edge/mobile devices
- is_realtime: real-time or near-realtime processing capable
- mentions_code: mentions code release/github link in abstract
- is_metaphorical: "sport"/"game" etc. used metaphorically (true -> discard)

## Paper List
{10 papers: index + title + abstract}

## Output
[{"index":1,"base_score":82,"flags":{"is_edge":true,"is_realtime":true,"mentions_code":false,"is_metaphorical":false},"discard":false,"brief_reason":"Korean 1-sentence"}]
